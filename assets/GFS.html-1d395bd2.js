import{_ as t,r as n,o,c as p,a as e,b as r,d as i,w as c,e as a}from"./app-20538318.js";const h={},d=a('<p>第二节课主要以代码的形式讲解了一下RPC以及golang并发编程，看完之后就可以完成lab1。这里直接开始第三节课。</p><h2 id="存储" tabindex="-1"><a class="header-anchor" href="#存储" aria-hidden="true">#</a> 存储</h2><p>还记的分布式系统的三大基础架构：存储，计算，通信。通过前两节的MapReduce和RPC，计算和通信已经讲解过了，这一节介绍了存储以及谷歌的解决方案GFS。</p><h3 id="设计难点" tabindex="-1"><a class="header-anchor" href="#设计难点" aria-hidden="true">#</a> 设计难点</h3><img src="https://blog-zzys.oss-cn-beijing.aliyuncs.com/articles/8dccf87f778e7fe8a913ac746db4ae66.png" style="zoom:80%;"><blockquote><p>并发性问题举例： W1写1，W2写2；R1和R2准备读取数据。W1和W2并发写，在不关心谁先谁后的情况下，考虑一致性，则我们希望R1和R2都读取到1或者都读取到2，R1和R2读取的值应该一致。（可通过分布式锁等机制解决）</p><p>故障/失败问题举例：</p><p>一般为了容错性，会通过复制的方式解决。而不成熟的复制操作，会导致读者在不做修改的情况下读取到两次不同的数据。比如，我们要求所有写者写数据时，需要往S1和S2都写一份。此时W1和W2并发地分别写1和2到S1、S2，而R1和R2即使在W1和W2都完成写数操作后，再从S1或S2读数时结果可能是1也可能是2（因为没有明确的协议指出这里W1和W2的数据在S1、S2上以什么方式存储，可能1被2覆盖，反之亦然）。</p></blockquote><h2 id="gfs" tabindex="-1"><a class="header-anchor" href="#gfs" aria-hidden="true">#</a> GFS</h2><p>每一个分布式系统都是按照它的应用场景的特点来设计的，GFS就是为MapReduce而设计的。在这里，需要的是高吞吐，高性能，且有容错。</p>',8),u={href:"http://nil.csail.mit.edu/6.824/2021/papers/gfs.pdf",target:"_blank",rel:"noopener noreferrer"},m=a('<h3 id="特征" tabindex="-1"><a class="header-anchor" href="#特征" aria-hidden="true">#</a> 特征</h3><ul><li>big data set</li><li>fast：automatic sharding</li><li>global：for all apps GFS has the same view</li><li>FT：automatic recover</li></ul><h3 id="数据读取" tabindex="-1"><a class="header-anchor" href="#数据读取" aria-hidden="true">#</a> 数据读取</h3><p><img src="https://blog-zzys.oss-cn-beijing.aliyuncs.com/articles/463035f220b0d89d6b1133e027f9a2b4.png" alt="image-20230920211527665" loading="lazy"></p><h3 id="master" tabindex="-1"><a class="header-anchor" href="#master" aria-hidden="true">#</a> Master</h3><p>在GFS设计中master是single system，并且为了能够更快的响应，数据存放在内存中。</p><p>数据：</p>',7),f=e("li",null,[e("p",null,"filename <---> chunk handle")],-1),_=e("li",null,[e("p",null,"chunk handle <---> version + List of chunk server")],-1),y=e("li",null,[e("p",null,"chunk server <---> primary server + some secondaries server"),e("ul",null,[e("li",null,"primary server 还存放着租约事件，在这个事件内primary是有效的")])],-1),v=e("p",null,"其中，第一条和第二条中的version需要被安全的持久化起来，其他的可以通过和chunk server沟通获取。",-1),k=e("h3",{id:"读取",tabindex:"-1"},[e("a",{class:"header-anchor",href:"#读取","aria-hidden":"true"},"#"),r(" 读取")],-1),E={href:"https://ashiamd.github.io/docsify-notes/#/study/%E5%88%86%E5%B8%83%E5%BC%8F%E7%AD%96%E7%95%A5/MIT6.824%E7%BD%91%E8%AF%BE%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-01",target:"_blank",rel:"noopener noreferrer"},b=a('<ul><li><p>Client向Master发请求，要求读取X文件的Y偏移量的数据</p></li><li><p>Master回复Client，X文件Y偏移量相关的块句柄、块服务器列表、版本号(chunk handle, list of chunk servers, version)</p></li><li><p>Client 缓存cache块服务器列表(list of chunk servers)</p></li><li><p>Client从最近的服务器请求chunk数据(reads from closest servers)</p></li><li><p>被Client访问的chunk server检查version，version正确则返回数据</p></li></ul><h3 id="写入" tabindex="-1"><a class="header-anchor" href="#写入" aria-hidden="true">#</a> 写入</h3>',2),g={href:"https://ashiamd.github.io/docsify-notes/#/study/%E5%88%86%E5%B8%83%E5%BC%8F%E7%AD%96%E7%95%A5/MIT6.824%E7%BD%91%E8%AF%BE%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-01",target:"_blank",rel:"noopener noreferrer"},C=a("<ul><li><p>Client向Master发出请求，查询应该往哪里写入filename对应的文件。</p></li><li><p>Master查询filename到chunk handle映射关系的表，找到需要修改的chunk handle后，再查询chunk handle到chunk server数组映射关系的表，以list of chunk servers(primary、secondaries、version信息)作为Client请求的响应结果</p></li><li><p>接下去有两种情况，已有primary和没有primary(假设这是系统刚启动后不久，还没有primary)</p><p>有primary：继续后续流程</p><p>无primary</p></li><li><ul><li>master在chunk servers中选出一个作为primary，其余的chunk server作为secondaries。(暂时不考虑选出的细节和步骤)</li><li>master会增加version（每次有新的primary时，都需要考虑时进入了一个new epoch，所以需要维护新的version），然后向primary和secondaries发送新的version，并且会发给primary有效期限的租约lease。这里primary和secondaries需要将version存储到磁盘，否则重启后内存数据丢失，无法让master信服自己拥有最新version的数据(同理Master也是将version存储在磁盘中)。</li><li>Client发送数据到想写入的chunk servers(primary和secondaries)，有趣的是，这里Client只需访问最近的secondary，而这个被访问的secondary会将数据也转发到列表中的下一个chunk server，此时数据还不会真正被chunk severs存储。（即上图中间黑色粗箭头，secondary收到数据后，马上将数据推送到其他本次需要写的chunk server）</li></ul></li></ul><p>这么做提高了Client的吞吐量，避免Client本身需要消耗大量网络接口资源往primary和多个secondaries都发送数据。</p><ul><li><p>数据传递完毕后，Client向primary发送一个message，表明本次为append操作。primary此时需要做几件事：</p><ul><li>primary此时会检查version，如果version不匹配，那么Client的操作会被拒绝</li><li>primary检查lease是否还有效，如果自己的lease无效了，则不再接受任何mutation operations（因为租约无效时，外部可能已经存在一个新的primary了）</li><li>如果version、lease都有效，那么primary会选择一个offset用于写入</li><li>primary将前面接收到的数据写入稳定存储中</li></ul></li><li><p>primary发送消息到secondaries，表示需要将之前接收的数据写入指定的offset</p></li><li><p>secondaries写入数据到primary指定的offset中，并回应primary已完成数据写入</p></li><li><p>primary回应Client，你想append追加的数据已完成写入</p></li><li><p>当然，存在一些情况导致数据append失败，此时primary本身写入成功，但是后续存在某些/某个secondaries写入失败，此时会向Client返回错误error。Client遇到这种错误后，通常会retry整个流程直到数据成功append，这也就是所谓的最少一次语义(do at-least-once)。</p></li></ul>",3);function S(B,A){const s=n("ExternalLinkIcon"),l=n("RouterLink");return o(),p("div",null,[d,e("p",null,[r("假设有10台机器，而每一台机器的IO极限带宽为30MB/s，GFS就可以达到300MB/s的总带宽。"),e("a",u,[r("GFS的论文"),i(s)])]),m,e("ul",null,[f,_,y,e("li",null,[e("p",null,[r("log + checkpoint ，参见"),i(l,{to:"/code/basic/ostep/ostep-persistence.html"},{default:c(()=>[r("ostep-persistence")]),_:1}),r("中的崩溃日志一章。")])])]),v,k,e("p",null,[r("以下文字来源于"),e("a",E,[r("参考笔记"),i(s)]),r("。")]),b,e("p",null,[r("以下文字来源于"),e("a",g,[r("参考笔记"),i(s)]),r("。")]),C])}const F=t(h,[["render",S],["__file","GFS.html.vue"]]);export{F as default};
