import{_ as i,r as l,o as r,c as o,a as s,b as a,d as t,e as n}from"./app-20538318.js";const c={},p=n(`<p>本章主要讲了虚拟化CPU。</p><h2 id="进程抽象" tabindex="-1"><a class="header-anchor" href="#进程抽象" aria-hidden="true">#</a> 进程抽象</h2><p>错觉：在多程序运行的情况下，为何感觉上有无数的CPU可供使用？</p><p>OS通过虚拟化（virtualizing）CPU来提供这种错觉。其中使用了<strong>分时</strong>（time shareing）技术保证用户可以同时运行多道程序。但是它潜在的问题是性能，每个程序需要更多的时间去执行。</p><p>为了实现这种虚拟化，OS需要<strong>底层的机械机制</strong>（low-level machinery <strong>mechanisms</strong>）和<strong>智能的策略</strong>（ high-level <strong>policies</strong>）。</p><p>底层机械机制通常指的是构建底层的一些方法或协议去实现一部分需要的功能，例如<strong>上下文切换</strong>（context switch）。智能策略指的是能够帮助OS做出更好的抉择的一些算法，如<strong>调度算法</strong>（scheduling policy），决定当前执行哪个程序。</p><h3 id="进程" tabindex="-1"><a class="header-anchor" href="#进程" aria-hidden="true">#</a> 进程</h3><p>将操作系统为运行中的程序提供的抽象称之为<strong>进程</strong>（Process）。</p><p><strong>机器状态</strong>（machine state）： what a program can read or update when it is running.At any given time, what parts of the machine are important to the execution of this program?</p><p>进程的机器状态通常通过观察内存（memory），寄存器（registers），持久化设备（ persistent storage devices）例如I/O。</p><h3 id="进程-api" tabindex="-1"><a class="header-anchor" href="#进程-api" aria-hidden="true">#</a> 进程 API</h3><ul><li>create</li><li>destroy</li><li>wait</li><li>miscellaneous control</li><li>status</li></ul><p>fork,exec,wait,kill...</p><h3 id="进程的创建" tabindex="-1"><a class="header-anchor" href="#进程的创建" aria-hidden="true">#</a> 进程的创建</h3><p>将dist中的可执行程序变成进程，需要将程序和一些静态数据从disk中取出加载到主存中。注意在现代操作系统中，程序通常是<strong>懒加载</strong>（lazily）的，不会将所有代码一下全部加载进内存中。</p><img src="https://blog-zzys.oss-cn-beijing.aliyuncs.com/articles/46dc522656902c7d2415b79437d85054.png" alt="image-20230808160556598" style="zoom:50%;"><p>在加载过程中，OS还需要做很多事。</p><p>首先是为进程分配<strong>运行时栈</strong>（run-time stack），它保存了返回地址，本地变量，以及函数参数，有时还会用函数参数初始化堆栈。</p><p>其次还需要为程序初始化<strong>堆</strong>（heap），在C中，它保存着显示动态请求的内存（malloc，free）</p><p>同时还需要初始化有关I/O的信息。例如对于从命令行读取或打印在屏幕上。</p><p>在执行完初始化操作后，OS就会在入口点处（main）去启动程序，将控制权交给进程。</p><h3 id="进程的状态" tabindex="-1"><a class="header-anchor" href="#进程的状态" aria-hidden="true">#</a> 进程的状态</h3><p>对于进程的状态，简化后的形式将其分为三种：</p><img src="https://blog-zzys.oss-cn-beijing.aliyuncs.com/articles/b9e0294188c01f11c530c358c38e7757.png" alt="image-20230808162904400" style="zoom:50%;"><p>Running&lt;---&gt;Ready之间是由OS的调度机制决定。在运行中的程序如果发生了阻塞（如I/O）不在需要CPU，那么就会进入Blocked状态，直到有一些事件触发，就会重新回到Ready状态等待调度。</p><h3 id="数据结构" tabindex="-1"><a class="header-anchor" href="#数据结构" aria-hidden="true">#</a> 数据结构</h3><p>OS和其他进程一样也有自己的内存数据结构，最基础的就是<strong>进程列表</strong>（process list），保留了处于各种状态的进程，并在特定的场合对其进行特定的操作。下面的代码是一个示例PCB。</p><div class="language-c line-numbers-mode" data-ext="c"><pre class="language-c"><code><span class="token comment">// the registers xv6 will save and restore</span>
<span class="token comment">// to stop and subsequently restart a process</span>
<span class="token keyword">struct</span> <span class="token class-name">context</span> <span class="token punctuation">{</span>
    <span class="token keyword">int</span> eip<span class="token punctuation">;</span>
    <span class="token keyword">int</span> esp<span class="token punctuation">;</span>
    <span class="token keyword">int</span> ebx<span class="token punctuation">;</span>
    <span class="token keyword">int</span> ecx<span class="token punctuation">;</span>
    <span class="token keyword">int</span> edx<span class="token punctuation">;</span>
    <span class="token keyword">int</span> esi<span class="token punctuation">;</span>
    <span class="token keyword">int</span> edi<span class="token punctuation">;</span>
    <span class="token keyword">int</span> ebp<span class="token punctuation">;</span>
<span class="token punctuation">}</span><span class="token punctuation">;</span>
<span class="token comment">// the different states a process can be in</span>
<span class="token comment">// 注意ZOMBIE僵尸线程：已经退出但还没有被清理的状态。</span>
<span class="token keyword">enum</span> <span class="token class-name">proc_state</span> <span class="token punctuation">{</span> UNUSED<span class="token punctuation">,</span> EMBRYO<span class="token punctuation">,</span> SLEEPING<span class="token punctuation">,</span>
				RUNNABLE<span class="token punctuation">,</span> RUNNING<span class="token punctuation">,</span> ZOMBIE <span class="token punctuation">}</span><span class="token punctuation">;</span>
<span class="token comment">// the information xv6 tracks about each process</span>
<span class="token comment">// including its register context and state</span>
<span class="token keyword">struct</span> <span class="token class-name">proc</span> <span class="token punctuation">{</span>
    <span class="token keyword">char</span> <span class="token operator">*</span>mem<span class="token punctuation">;</span> <span class="token comment">// Start of process memory</span>
    uint sz<span class="token punctuation">;</span> <span class="token comment">// Size of process memory</span>
    <span class="token keyword">char</span> <span class="token operator">*</span>kstack<span class="token punctuation">;</span> <span class="token comment">// Bottom of kernel stack</span>
    <span class="token comment">// for this process</span>
    <span class="token keyword">enum</span> <span class="token class-name">proc_state</span> state<span class="token punctuation">;</span> <span class="token comment">// Process state</span>
    <span class="token keyword">int</span> pid<span class="token punctuation">;</span> <span class="token comment">// Process ID</span>
    <span class="token keyword">struct</span> <span class="token class-name">proc</span> <span class="token operator">*</span>parent<span class="token punctuation">;</span> <span class="token comment">// Parent process</span>
    <span class="token keyword">void</span> <span class="token operator">*</span>chan<span class="token punctuation">;</span> <span class="token comment">// If non-zero, sleeping on chan</span>
    <span class="token keyword">int</span> killed<span class="token punctuation">;</span> <span class="token comment">// If non-zero, have been killed</span>
    <span class="token keyword">struct</span> <span class="token class-name">file</span> <span class="token operator">*</span>ofile<span class="token punctuation">[</span>NOFILE<span class="token punctuation">]</span><span class="token punctuation">;</span> <span class="token comment">// Open files</span>
    <span class="token keyword">struct</span> <span class="token class-name">inode</span> <span class="token operator">*</span>cwd<span class="token punctuation">;</span> <span class="token comment">// Current directory</span>
    <span class="token keyword">struct</span> <span class="token class-name">context</span> context<span class="token punctuation">;</span> <span class="token comment">// Switch here to run process</span>
    <span class="token keyword">struct</span> <span class="token class-name">trapframe</span> <span class="token operator">*</span>tf<span class="token punctuation">;</span> <span class="token comment">// Trap frame for the</span>
    <span class="token comment">// current interrupt</span>
<span class="token punctuation">}</span><span class="token punctuation">;</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div>`,28),d=s("p",null,"进程控制块（Process Control Block）：用于存储进程信息的结构，每个进程都有一个对应的PCB",-1),m={href:"https://zhuanlan.zhihu.com/p/654235321",target:"_blank",rel:"noopener noreferrer"},u=n('<h2 id="受限的直接访问" tabindex="-1"><a class="header-anchor" href="#受限的直接访问" aria-hidden="true">#</a> 受限的直接访问</h2><p>在虚拟化CPU的过程中，会遇到两个矛盾点：性能以及控制，如何在OS保证对程序的控制的同时而不去增加过多的开销。在这里OS就需要使用一些硬件支持来完成任务。</p><h3 id="直接访问" tabindex="-1"><a class="header-anchor" href="#直接访问" aria-hidden="true">#</a> 直接访问</h3><p>直接访问即让程序在CPU上直运行，流程如下图和上文进程的创建是很像的：</p><img src="https://blog-zzys.oss-cn-beijing.aliyuncs.com/articles/dfe9cb24cc95acda1e4030c09fac30a8.png" alt="image-20230808173708296" style="zoom:67%;"><p>但是这里就有两个问题：</p><ul><li><p>操作系统如何能确保该程序不做任何我们不希望它做的事情，同时仍然有效地运行它。</p></li><li><p>操作系统如何在合适的事件阻止它运行并切换到另一个进程，从而实现虚拟化CPU所需的分时共享。</p></li></ul><h3 id="受限操作" tabindex="-1"><a class="header-anchor" href="#受限操作" aria-hidden="true">#</a> 受限操作</h3><p>上面的方式由于原生的运行在CPU上，速度很快，但是思考下面的场景，一个进程必须能够执行I/O（如读取或写入文件）和其他一些受限制的操作，但不可以拥有系统的完全控制。操作系统和硬件如何协同做到这一点？</p><p>所以在这里引出了一种新的处理器模式，称为<strong>用户模式</strong>（user mode）。在用户模式下运行的代码被限制在它所能做的事情上。例如，在用户模式下运行时，进程不能发出I/O请求；这样做会导致处理器引发异常；然后操作系统可能会杀死这个进程。</p><p>与用户模式相反的是<strong>内核模式</strong>（kernel mode），操作系统（或内核）运行在它中。在这种模式下，运行的代码可以做任何事情，包括特权操作，如发出I/O请求和执行所有类型的受限指令。</p><p>所以当用户进程希望执行某种特权操作时，比如从磁盘读取，它应该做什么？这里就借用了硬件支持用户程序<strong>系统调用</strong>（system call）。</p><p>要执行一个系统调用，一个程序必须执行一个特殊的<strong>陷阱</strong>（trap）指令。该指令同时跳入内核，并将特权级别提升到内核模式；一旦进入内核，系统现在就可以执行所需的任何特权操作（如果允许的话），从而为调用进程执行所需的工作。完成后，操作系统会调用一个特殊的<strong>陷阱返回</strong>（return-from-trap）指令，它会返回到调用用户程序中，同时将特权级别降低回用户模式。</p><p>当从用户态陷入内核态时，会将一些用户态的信息压入<strong>内核栈</strong>（kernel stack）中，设置栈指针寄存器的内容为内核栈的地址。从陷阱返回将把这些值从堆栈中弹出，将保存在内核栈里面的用户栈的地址恢复到堆栈指针寄存器，恢复用户态模式程序的执行。</p>',14),g={href:"https://www.cnblogs.com/dormant/p/5456491.html",target:"_blank",rel:"noopener noreferrer"},h=n('<p>但是，硬件是怎么知道当用户态的程序陷入内核态时，需要执行那些代码呢？</p><p>内核会在引导式设置一个<strong>陷阱表</strong>（trap table）来实现这一点，操作系统做的第一件事是告诉硬件在某些异常事件发生时要运行哪些代码。例如，当硬盘中断发生、键盘中断发生或程序进行系统调用时，应该运行什么代码。一旦硬件被通知，它就会记住这些处理程序的位置，直到机器下次重新启动，因此当系统调用和其他异常事件发生时，硬件知道该做什么（即要跳转到什么代码）。</p><p>下图是对上面的描述：</p><img src="https://blog-zzys.oss-cn-beijing.aliyuncs.com/articles/e2f1eda2735093c7009fff30c17138a5.png" alt="image-20230808183342127" style="zoom:67%;"><p>用户态和内核态通过陷阱相连，由硬件控制整个过程。</p><h3 id="上下文切换" tabindex="-1"><a class="header-anchor" href="#上下文切换" aria-hidden="true">#</a> 上下文切换</h3><p>下面一个问题就是实现对于进程之间的切换。这里首先引出一个问题，对于其他的程序占用CPU，也就意味着OS没有被运行。如何才能够使得OS重新获得CPU的使用权呢？</p><h4 id="os获取cpu使用权" tabindex="-1"><a class="header-anchor" href="#os获取cpu使用权" aria-hidden="true">#</a> OS获取CPU使用权</h4><p>一种是合作的方法，OS会信任程序可以合理的运行，并且可以周期性的放弃CPU占用，通常是在一个程序使用了系统调用（yield），陷入内核态时。或者是程序有非法行为，也会生成一个陷阱使得OS可以再次操作CPU。但是很明显，当程序陷入无限循环后，这种方式就失效了。</p><p>另一种是非合作的方式，<strong>计时器中断</strong>（timer interrupt），通过一个定时器设备，在每隔几毫秒会引起一次中断，当中断被引发时，当前程序停止运行，OS运行预先配置的<strong>中断处理</strong>（interrupt handler）程序，此时，操作系统就获取到了CPU的使用权。</p><p>和系统调用类似，在启动时OS必须通知硬件在中断时要执行哪些代码。同时启动计时器。</p><p>当中断发生时，硬件需要在中断发生时保存足够的程序的状态，以便后续返回指令将能够正确恢复运行的程序。这组操作非常类似于硬件在进入内核的显式系统调用陷阱期间的行为，各种寄存器因此被保存，因此很容易通过从陷阱返回的指令恢复。</p><h4 id="状态保存" tabindex="-1"><a class="header-anchor" href="#状态保存" aria-hidden="true">#</a> 状态保存</h4><p>在OS可以获取到CPU的使用权后，接下来就是上下文切换的问题了，如果操作系统决定要进行线程切换，为了保存当前运行的进程的上下文，操作系统将执行一些低级程序集代码来保存通用寄存器PC以及当前运行进程的内核栈指针，然后恢复将要执行进程的寄存器PC，并切换到内核堆栈指针。通过切换堆栈，内核进入在一个进程（被中断的进程）的上下文中调用switch代码，并在另一个进程的上下文（即将执行的上下文）中返回。当操作系统最终执行一个从陷阱返回的指令时，即将执行的进程将成为当前运行的进程。</p><p>在此过程中，有两种类型的寄存器保存/恢复。第一个是计时器中断发生时（普通的系统调用也会发生），在这种情况下，正在运行的进程的用户态信息（寄存器信息）由硬件<strong>隐式保存到该进程的内核堆栈</strong>。第二种情况是当操作系统决定从切换时；在这种情况下，是内核寄存器状态被软件（即操作系统）<strong>显式</strong>保存，<strong>但这一次被保存到进程结构中的内存中</strong>。</p><blockquote><p>第一种寄存器变更并不算上下文切换，从始至终都是同一个进程在执行。</p></blockquote><p>下图是对上面的总结：</p><img src="https://blog-zzys.oss-cn-beijing.aliyuncs.com/articles/80690548a0146e36c58846bf36a07d03.png" alt="image-20230808220149243" style="zoom:50%;"><p>所示红圈即为两次寄存器保存。</p><h3 id="并发中断" tabindex="-1"><a class="header-anchor" href="#并发中断" aria-hidden="true">#</a> 并发中断</h3><p>有一种情况是当系统调用时触发中断或在中断时再次中断怎么办，操作系统可能会做的一件简单的事情是在中断处理过程中禁用中断；这样做可以确保当一个中断被处理时，没有其他的中断将被传递到CPU。</p><h2 id="调度" tabindex="-1"><a class="header-anchor" href="#调度" aria-hidden="true">#</a> 调度</h2><p>在了解了底层机制后，就需要对高层的<strong>调度策略</strong>（scheduling policies）进行研究。这里需要引入衡量调度策略的指标。</p><h3 id="workload" tabindex="-1"><a class="header-anchor" href="#workload" aria-hidden="true">#</a> workload</h3><p>对系统进程做出一些合理化假设，使得问题简化，称之为workload（找不到好翻译）。慢慢的完善假设，最终构建出一个<strong>全面运行的调度规则</strong>（fully-operational scheduling discipline）。</p><p>在这里将进程称之为<strong>作业</strong>（job），下面是对进程4个假设：</p><ol><li><p>每个作业运行所需要的时间都相同。</p></li><li><p>所有的工作都需要同时调用（同时到达）。</p></li><li><p>所有作业都只使用CPU（即不执行I/O)</p></li><li><p>每个作业的运行时长都是已知的。</p></li></ol><h3 id="调度指标" tabindex="-1"><a class="header-anchor" href="#调度指标" aria-hidden="true">#</a> 调度指标</h3><p>除了假设工作负载之外，还需要另外能够比较不同的调度策略：<strong>周转时间</strong>（<strong>scheduling metric</strong>）:</p><p>$ T_{turnaround} = T_{completion} − T_{arrival}$</p><p>即周转时间等于作业完成时间减去作业到达时间。很明显它是一个性能指标。</p><p>另一个重要的指标是<strong>公平性</strong>（fairness），调度器可以优化性能，但以阻止一些作业运行为代价，从而降低公平性。所以公平性和性能通常是不一致的。</p><h3 id="fifo" tabindex="-1"><a class="header-anchor" href="#fifo" aria-hidden="true">#</a> FIFO</h3><p>FIFO，即先到先服务、先进先出，在当前的假设下，它即容易实现，又工作的很好，对于如下的情况：</p><img src="https://blog-zzys.oss-cn-beijing.aliyuncs.com/articles/9df470027b36de582c1a9e06305ac754.png" alt="image-20230809143946335" style="zoom:67%;"><p>可以计算出<strong>平均周转时间</strong>（average turnaround time）为</p>',36),b=s("p",null,[s("span",{class:"katex"},[s("span",{class:"katex-mathml"},[s("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[s("semantics",null,[s("mrow",null,[s("mo",{stretchy:"false"},"("),s("mn",null,"10"),s("mo",null,"+"),s("mn",null,"20"),s("mo",null,"+"),s("mn",null,"30"),s("mo",{stretchy:"false"},")"),s("mi",{mathvariant:"normal"},"/"),s("mn",null,"3"),s("mo",null,"="),s("mn",null,"20")]),s("annotation",{encoding:"application/x-tex"},"(10+20+30)/3=20")])])]),s("span",{class:"katex-html","aria-hidden":"true"},[s("span",{class:"base"},[s("span",{class:"strut",style:{height:"1em","vertical-align":"-0.25em"}}),s("span",{class:"mopen"},"("),s("span",{class:"mord"},"10"),s("span",{class:"mspace",style:{"margin-right":"0.2222em"}}),s("span",{class:"mbin"},"+"),s("span",{class:"mspace",style:{"margin-right":"0.2222em"}})]),s("span",{class:"base"},[s("span",{class:"strut",style:{height:"0.7278em","vertical-align":"-0.0833em"}}),s("span",{class:"mord"},"20"),s("span",{class:"mspace",style:{"margin-right":"0.2222em"}}),s("span",{class:"mbin"},"+"),s("span",{class:"mspace",style:{"margin-right":"0.2222em"}})]),s("span",{class:"base"},[s("span",{class:"strut",style:{height:"1em","vertical-align":"-0.25em"}}),s("span",{class:"mord"},"30"),s("span",{class:"mclose"},")"),s("span",{class:"mord"},"/3"),s("span",{class:"mspace",style:{"margin-right":"0.2778em"}}),s("span",{class:"mrel"},"="),s("span",{class:"mspace",style:{"margin-right":"0.2778em"}})]),s("span",{class:"base"},[s("span",{class:"strut",style:{height:"0.6444em"}}),s("span",{class:"mord"},"20")])])])],-1),k=n('<p>那么现在去掉假设一，每个程序运行所需的时间不相同，这样就会出现一些问题：</p><img src="https://blog-zzys.oss-cn-beijing.aliyuncs.com/articles/599ec312cdfd2e8bbdfd15752be90055.png" alt="image-20230809144307112" style="zoom:50%;"><p>如果先到达的程序需要运行的时间较长，平均周转时间就会增长到110，这种情况称之为<strong>护航效应</strong>（convoy effect）。</p><h3 id="shortest-job-first" tabindex="-1"><a class="header-anchor" href="#shortest-job-first" aria-hidden="true">#</a> Shortest Job First</h3><p>SJF，即最短作业优先，很简单，就是所需最短时间的作业先执行，这样作业的排列顺序就如下图：</p><img src="https://blog-zzys.oss-cn-beijing.aliyuncs.com/articles/d00f386680e698f8f8076ac726662fa8.png" alt="image-20230809144847221" style="zoom:50%;"><p>平均周转时间从110降到了50。</p><p>那么现在去掉假设二，如果作业到达的顺序不同呢？A就有可能排到了最前面，那么周转时间又一次的逼近了110。</p><img src="https://blog-zzys.oss-cn-beijing.aliyuncs.com/articles/88e9ee3db17596d752d2e1822cbaacb9.png" alt="image-20230809145150018" style="zoom:50%;"><h3 id="shortest-time-to-completion-first" tabindex="-1"><a class="header-anchor" href="#shortest-time-to-completion-first" aria-hidden="true">#</a> Shortest Time-to-Completion First</h3><p>STCF，即最短完成时间，由于上面已经有了关于计时器中断、上下文切换等底层机制，OS就可以决定在B、C到达时，是否<strong>抢占</strong>（preempt）作业A。如下图：</p><img src="https://blog-zzys.oss-cn-beijing.aliyuncs.com/articles/ee1b77c276ec16d98fc291842e0721d4.png" alt="image-20230809145720813" style="zoom:50%;"><p>每当一个新作业进入系统时，它都会确定剩余的作业和新作业，它们谁剩下的时间最少，然后调度该作业。</p><p>这样又一次将平均周转时间降到了50。</p><p>但是现在又有一个指标被引入：<strong>响应时间</strong>（response time），由于分时机器的引入。现在，用户也会坐在终端前，要求系统的交互性能。响应时间按被定义为作业第一次被调度的时间减去到达时间。</p>',15),y=s("p",null,[s("span",{class:"katex"},[s("span",{class:"katex-mathml"},[s("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[s("semantics",null,[s("mrow",null,[s("msub",null,[s("mi",null,"T"),s("mrow",null,[s("mi",null,"r"),s("mi",null,"e"),s("mi",null,"s"),s("mi",null,"p"),s("mi",null,"o"),s("mi",null,"n"),s("mi",null,"s"),s("mi",null,"e")])]),s("mo",null,"="),s("mi",null,"T"),s("mrow",null,[s("mi",null,"f"),s("mi",null,"i"),s("mi",null,"r"),s("mi",null,"s"),s("mi",null,"t"),s("mi",null,"r"),s("mi",null,"u"),s("mi",null,"n")]),s("mo",null,"−"),s("mi",null,"T"),s("mrow",null,[s("mi",null,"a"),s("mi",null,"r"),s("mi",null,"r"),s("mi",null,"i"),s("mi",null,"v"),s("mi",null,"a"),s("mi",null,"l")])]),s("annotation",{encoding:"application/x-tex"},"T_{response} = T{firstrun} − T{arrival}")])])]),s("span",{class:"katex-html","aria-hidden":"true"},[s("span",{class:"base"},[s("span",{class:"strut",style:{height:"0.9694em","vertical-align":"-0.2861em"}}),s("span",{class:"mord"},[s("span",{class:"mord mathnormal",style:{"margin-right":"0.13889em"}},"T"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.1514em"}},[s("span",{style:{top:"-2.55em","margin-left":"-0.1389em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mtight"},[s("span",{class:"mord mathnormal mtight"},"res"),s("span",{class:"mord mathnormal mtight"},"p"),s("span",{class:"mord mathnormal mtight"},"o"),s("span",{class:"mord mathnormal mtight"},"n"),s("span",{class:"mord mathnormal mtight"},"se")])])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.2861em"}},[s("span")])])])])]),s("span",{class:"mspace",style:{"margin-right":"0.2778em"}}),s("span",{class:"mrel"},"="),s("span",{class:"mspace",style:{"margin-right":"0.2778em"}})]),s("span",{class:"base"},[s("span",{class:"strut",style:{height:"0.8889em","vertical-align":"-0.1944em"}}),s("span",{class:"mord mathnormal",style:{"margin-right":"0.13889em"}},"T"),s("span",{class:"mord"},[s("span",{class:"mord mathnormal",style:{"margin-right":"0.10764em"}},"f"),s("span",{class:"mord mathnormal"},"i"),s("span",{class:"mord mathnormal"},"rs"),s("span",{class:"mord mathnormal"},"t"),s("span",{class:"mord mathnormal",style:{"margin-right":"0.02778em"}},"r"),s("span",{class:"mord mathnormal"},"u"),s("span",{class:"mord mathnormal"},"n")]),s("span",{class:"mspace",style:{"margin-right":"0.2222em"}}),s("span",{class:"mbin"},"−"),s("span",{class:"mspace",style:{"margin-right":"0.2222em"}})]),s("span",{class:"base"},[s("span",{class:"strut",style:{height:"0.6944em"}}),s("span",{class:"mord mathnormal",style:{"margin-right":"0.13889em"}},"T"),s("span",{class:"mord"},[s("span",{class:"mord mathnormal"},"a"),s("span",{class:"mord mathnormal",style:{"margin-right":"0.02778em"}},"rr"),s("span",{class:"mord mathnormal"},"i"),s("span",{class:"mord mathnormal",style:{"margin-right":"0.03588em"}},"v"),s("span",{class:"mord mathnormal"},"a"),s("span",{class:"mord mathnormal",style:{"margin-right":"0.01968em"}},"l")])])])])],-1),v=n('<p>对于类似于STCF之类的调度算法，它对于响应时间时不敏感的。如果三个作业同时到达，第三个必须等待前两个作业结束后才可以被调度，尽管前两个的运行时间小于第三个，但也是不可控的。</p><h3 id="round-robin" tabindex="-1"><a class="header-anchor" href="#round-robin" aria-hidden="true">#</a> Round Robin</h3><p>RR，即轮询。RR不是运行作业完成，而是<strong>时间片</strong>（time slice），有时称为<strong>调度量</strong>（cheduling quantum），然后切换到运行队列中的下一个作业。它会重复这样做，直到作业完成。因此，RR有时被称为<strong>时间分割</strong>（time slicing）。在这里，时间片的长度必须是定时器中断周期的倍数；因此，如果计时器每10毫秒中断一次，则时间片可以是10、20或任何其他10 ms的倍数。</p><img src="https://blog-zzys.oss-cn-beijing.aliyuncs.com/articles/9945a1ac6395d654c9252eae18bf7a98.png" alt="image-20230809151102682" style="zoom:67%;"><p>这样，响应时间就和时间片的长度呈正相关，时间片越短，响应时间越短。同时，上下文切换也越频繁，性能也将下降。</p><blockquote><p>CPU亲和性：上下文切换的成本并不仅仅来自于保存和恢复一些寄存器的操作系统操作。当程序运行时，它们在CPU缓存、TLB、分支预测器和其他片上硬件中建立了大量的状态。切换到另一个作业会导致刷新此状态，并引入与当前正在运行的作业相关的新状态，这可能会导致明显的性能成本上升。</p></blockquote><p>但是，如果时间分片是1，对于上图的平均周转时间，就达到了14，相较于SJF的10，再加上上下文切换的成本，上升还是很大的。 这种就是公平和性能之间的权衡。</p><h3 id="incorporating-i-o" tabindex="-1"><a class="header-anchor" href="#incorporating-i-o" aria-hidden="true">#</a> Incorporating I/O</h3><p>一个程序对于输入输出是必然需要的，当程序进行I/O时，是不占用CPU的，那么它就会被<strong>阻塞</strong>（blocked）等待I/O结束，这时，调度程序可能在CPU上调度下一个作业。如下图：</p><img src="https://blog-zzys.oss-cn-beijing.aliyuncs.com/articles/131319c7a2658b82c051679394c50820.png" alt="image-20230809155336573" style="zoom:67%;"><p>当A在等待I/O时，调度系统将CPU的使用权交给B，当A阻塞结束后，重新进入调度中。也就是将A分成了一个一个的子作业。</p><p>对于最后一个假设，通过构建一个调度程序被称为<strong>多级反馈队列</strong>（multi-level feedback queue，MLFQ）来处理。</p><h2 id="多级反馈队列调度" tabindex="-1"><a class="header-anchor" href="#多级反馈队列调度" aria-hidden="true">#</a> 多级反馈队列调度</h2><p>MLFQ试图解决的基本问题有两方面。它希望优化周转时间，并且最小化响应时间。</p><p>MLFQ有许多不同的<strong>队列</strong>（queue），每个队列都被分配了不同的<strong>优先级</strong>（priority level）。在任何给定的时间，准备运行的作业都在单个队列上。MLFQ使用优先级来决定在给定的时间应该运行哪个作业：选择具有更高优先级的作业（即在更高队列上的作业）来运行。同时，在相同优先级队列上的作业，使用RR调度。</p><p>因此，MLFQ调度的关键在于调度器如何设置优先级。MLFQ并没有给每个作业一个固定的优先级，而是根据其观察到的行为来改变作业的优先级。例如，如果一个作业在等待键盘输入时反复放弃CPU，MLFQ将保持其高优先级，因为这可能是交互过程的行为方式。相反，如果一个作业长时间集中使用CPU，MLFQ将降低其优先级。通过这种方式，MLFQ将尝试了解正在运行的进程，从而使用作业的历史记录来预测其未来的行为。</p><p>这样，就有了两条规则：</p><ul><li><p><strong>Rule 1:</strong> If Priority(A) &gt; Priority(B), A runs (B doesn’t).</p></li><li><p><strong>Rule 2:</strong> If Priority(A) = Priority(B), A &amp; B run in RR.</p></li></ul><p>那么在现在看来，MLFQ的状态有可能是下图：</p><img src="https://blog-zzys.oss-cn-beijing.aliyuncs.com/articles/63643379e57705e830bad607d8ab436c.png" alt="image-20230809164430628" style="zoom:67%;"><p>但是很显然由于规则一，C和D将不会被执行，会存在饥饿的问题。所以，引入第一次改变。</p><h3 id="改变优先级" tabindex="-1"><a class="header-anchor" href="#改变优先级" aria-hidden="true">#</a> 改变优先级</h3><p>假设我们由两种作业，一种是短期的交互式作业（响应时间敏感），由于系统I/O，可能会放弃CPU使用。一种是CPU密集型的长时间占用CPU的CPU绑定型作业（对响应时间不敏感）。</p><p>下面引入两条规则：</p><ul><li><p><strong>Rule 3:</strong> 当作业进入系统时，作业将处于最高优先级（最高队列）。</p></li><li><p><strong>Rule 4a:</strong> 如果作业在运行时耗尽了整个时间片，其优先级将降低（它向下移动一个队列）。</p></li><li><p><strong>Rule 4b:</strong> 如果作业在时间片出现之前放弃CPU，它保持在相同的优先级。</p></li></ul><p>下面举三个例子：</p><ol><li><p>CPU密集型作业：</p><img src="https://blog-zzys.oss-cn-beijing.aliyuncs.com/articles/389245a9e1b98ee8d4cc52cfa0ddaf4b.png" alt="image-20230809165129748" style="zoom:67%;"></li><li><p>短暂性工作</p><img src="https://blog-zzys.oss-cn-beijing.aliyuncs.com/articles/f3040642fe6b09f019d33ca9348499fe.png" alt="image-20230809165248274" style="zoom:67%;"><p>可以看到，当高优先级作业到达时，便会将CPU的使用权从低优先级作业中转移。</p></li><li><p>I/O操作</p><img src="https://blog-zzys.oss-cn-beijing.aliyuncs.com/articles/19f9a268e09f38474a2137862a4e7d7f.png" alt="image-20230809165440269" style="zoom:67%;"><p>如果一个交互式作业做了大量的I/O（例如等待用户从键盘或鼠标输入），它将在其时间片完成之前放弃CPU。这样我们并不希望降低它的优先级。</p></li></ol><p>但是现在还存在一些问题：</p><ol><li><p>当交互性作业过多时，底优先级的作业将永远无法执行，被称为<strong>饥饿</strong>（starvation）。</p></li><li><p>不良用户将会利用4.a，4.b的规则，在时间片快要耗尽时，放弃CPU（I/O）以获得更高百分比的CPU时间。</p></li><li><p>一个程序可能会随着时间的推移而改变其行为（由CPU密集转变为交互式）但是我们并没有优先级上升的方式。</p></li></ol><h3 id="优先级提升" tabindex="-1"><a class="header-anchor" href="#优先级提升" aria-hidden="true">#</a> 优先级提升</h3><p>这里可以使用最简单的方式：</p>',31),f=s("ul",null,[s("li",null,[s("strong",null,"Rule 5:"),a(" 经过一段时间段 "),s("span",{class:"katex"},[s("span",{class:"katex-mathml"},[s("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[s("semantics",null,[s("mrow",null,[s("mi",null,"S")]),s("annotation",{encoding:"application/x-tex"},"S")])])]),s("span",{class:"katex-html","aria-hidden":"true"},[s("span",{class:"base"},[s("span",{class:"strut",style:{height:"0.6833em"}}),s("span",{class:"mord mathnormal",style:{"margin-right":"0.05764em"}},"S")])])]),a(" 后，将系统中的所有作业移到最顶层的队列中。")])],-1),z=n(`<p>这样就解决了上面的第一个和第三个问题，下面是例子：</p><ol><li><p>对于处在底层的作业，不会发生饥饿，长时间无法获取CPU使用</p><img src="https://blog-zzys.oss-cn-beijing.aliyuncs.com/articles/3f32cc737b020bb90bf9aaf772a97def.png" alt="image-20230809170612513" style="zoom:50%;"></li><li><p>对于作业形式的转变，在优先级提升后，调度程序会根据规则4正确的对待。</p><img src="https://blog-zzys.oss-cn-beijing.aliyuncs.com/articles/625abdd2dc3a828d9a5326101f9aa23d.png" alt="image-20230809170811674" style="zoom:50%;"></li></ol><blockquote><p>S 的设置，称之为 <strong>voo-doo constants</strong>, If it is set too high, long-running jobs could starve; too low, and interactive jobs may not get a proper share of the CPU.</p></blockquote><h3 id="优化计算" tabindex="-1"><a class="header-anchor" href="#优化计算" aria-hidden="true">#</a> 优化计算</h3><p>针对欺骗问题，这里对CPU使用时间的计算进行了优化，有了以下规则：</p><ul><li><strong>Rule 4:</strong> 一旦一个作业耗尽了给定级别的时间分配（不管它放弃了多少次），它的优先级就会降低（向下移动一个队列）。</li></ul><img src="https://blog-zzys.oss-cn-beijing.aliyuncs.com/articles/0f94d2cace30d61730d7aad750723422.png" alt="image-20230809171643621" style="zoom:67%;"><blockquote><p>在MLFQ调度中还出现了其他一些问题。一个大问题是如何参数化这样的调度器。例如，应该有多少个队列？每个队列的时间片应该有多大？为了避免饥饿和解释行为的变化，应该多久增加一次优先级？这些问题没有简单的答案，因此只有一些关于工作负载和后续调度器调优的经验才能导致令人满意的平衡。例如，大多数MLFQ变体允许在不同的队列中改变时间片长度。高优先级队列通常有较短的时间切片；毕竟，它们由交互式作业组成，因此在它们之间快速交替是有意义的（例如，10毫秒或更少毫秒）。相比之下，低优先级队列包含CPU绑定的长运行作业；因此，较长的时间片工作得很好（例如，100秒毫秒）。许多调度程序还有一些您可能会遇到的其他特性。例如，一些调度程序为操作系统的工作保留了最高的优先级；因此，典型的用户作业永远无法在系统中获得最高的优先级。有些系统还允许一些用户建议来帮助设置优先级；例如，通过使用命令行实用程序nice，您可以增加或减少作业的优先级（有些程度上），从而增加或减少作业在任何给定时间运行的机会。</p></blockquote><h2 id="比例份额调度" tabindex="-1"><a class="header-anchor" href="#比例份额调度" aria-hidden="true">#</a> 比例份额调度</h2><p>取代于上面的调度，<strong>比例份额</strong>（proportional share）调度会去保证每一个程序可以获取到一定百分比的CPU时间。最典型的例子是<strong>彩票</strong>（lottery）调度。</p><h3 id="彩票数决定份额" tabindex="-1"><a class="header-anchor" href="#彩票数决定份额" aria-hidden="true">#</a> 彩票数决定份额</h3><p>彩票调度最基本的概念是<strong>彩票</strong>（tickets），它代表了一个程序应该接收到的资源共享，程序所拥有的彩票的百分比表示其对系统资源的份额。</p><p>例子：A和B程序，A有75张票，而B只有25张。因此，A获得75%的CPU，而B接收剩下的25%。彩票程序在每一次时间片结束后，进行选票，假设五次选票结果如下： 43，23，88，56，44 。那么调度结果就是：A、A、B、A、A。程序A获取到了CPU的80%的时间，随着竞争的时间加长，概率会越来越接近期望值。</p><blockquote><p>彩票调度是基于<strong>随机性</strong>（randomness）的，随机性相比较于传统的调度有三个优势：</p><ul><li>随机通常可以避免出现像一个更传统的算法可能出现的难以处理的奇怪的边角情况行为。、</li><li>随机也是轻量级的，需要很少的状态来跟踪替代方案</li><li>随机性的速度可以相当快，需求越快，随机就越倾向于<strong>伪随机</strong>（pseudo-random）</li></ul></blockquote><h3 id="彩票机制" tabindex="-1"><a class="header-anchor" href="#彩票机制" aria-hidden="true">#</a> 彩票机制</h3><p>第一种彩票机制是<strong>彩票货币</strong>（ticket currency），允许拥有一组彩票的用户以他们自己的某种货币，将彩票分给自己的不同工作。之后OS再自动将这种货币兑换为正确的全局彩票。</p><div class="language-text line-numbers-mode" data-ext="text"><pre class="language-text"><code>User A  -&gt; 500 (A’s currency) to A1 -&gt; 50 (global currency)
		-&gt; 500 (A’s currency) to A2 -&gt; 50 (global currency)
User B  -&gt; 10 (B’s currency) to B1 -&gt; 100 (global currency)
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>A将自己的彩票一般分给A1，一般分给A2。用户B将自己的彩票全部分给B1。随后OS就将所有的彩票统一处理，得到全局彩票值。</p><p>另一种机制是<strong>彩票转换</strong>（ticket transfer）：，一个进程可以临时将自己的彩票交给另一个进程。这种机制在客户端/服务端交互的场景中尤其有用。</p><p>最后一种是<strong>彩票通胀</strong>（ticket inflation）。利用通胀，一个进程可以临时提升或降低自己拥有的彩票数量。通胀可以用于进程之间相互信任的环境。在竞争环境中，进程之间互相不信任，这种机制就没什么意义。</p><h3 id="实现" tabindex="-1"><a class="header-anchor" href="#实现" aria-hidden="true">#</a> 实现</h3><p>只需要一个不错的随机数生成器来选择中奖彩票和一个记录系统中所有进程的数据结构（一个列表），以及所有彩票的总数就可以实现彩票调度。假定我们用列表记录进程，如下图：</p><img src="https://blog-zzys.oss-cn-beijing.aliyuncs.com/articles/b7858087076a3495d99108016e64a6e1.png" alt="image-20230811084048585" style="zoom:80%;"><p>下面是实现代码：</p><div class="language-c++ line-numbers-mode" data-ext="c++"><pre class="language-c++"><code>// 当前遍历到的值
int counter = 0;

// 使用一个随机数代表赢票值，范围是0到totaltickets
int winner = getrandom(0, totaltickets);

// 使用current遍历程序链表
node_t *current = head;

// 遍历程序，直到找到赢票属于哪一个程序
while (current) {
  counter = counter + current-&gt;tickets;
  if (counter &gt; winner)
    break; // 找到赢票程序
  current = current-&gt;next;
}
// 赢票程序被调度
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>通常会将其优化，从更多的票排序向少的票，这样增大了在前面找到赢家的概率，降低了平均循环次数。</p><h3 id="彩票机制的问题" tabindex="-1"><a class="header-anchor" href="#彩票机制的问题" aria-hidden="true">#</a> 彩票机制的问题</h3><p>这里考虑两个竞争的程序A、B，各自都有100张票，它们的运行时间分别是R1、R2 。<strong>不公平衡量标准</strong>（unfairness metric）U代表了它们之间的比例，通常将U趋近于1称之更加公平。</p><img src="https://blog-zzys.oss-cn-beijing.aliyuncs.com/articles/c64b7784508fef9a4fdfa175fa7e2f0a.png" alt="image-20230811090526160" style="zoom:50%;"><p>如上图，对于平均长度越短的程序之间的U值越小，代表着越不公平。也就是说彩票调度不会给我们带来精确的比例，特别是在短时间尺度上。</p><h3 id="步长调度" tabindex="-1"><a class="header-anchor" href="#步长调度" aria-hidden="true">#</a> 步长调度</h3><p>步长调度（stride scheduling,）是一种确定性的公平共享调度器。它有两个值，一是<strong>步长值</strong>（stride value），这个值与票数值成反比（取各票数的一个较大公倍数/各票数）。二是<strong>行程值</strong>（pass value）。</p><p>当需要进行调度时，选择目前拥有最小行程值的进程，并且在运行之后将该进程的行程值增加一个步长。</p><div class="language-c++ line-numbers-mode" data-ext="c++"><pre class="language-c++"><code>current = remove_min(queue); // 选择行程值最小的进程
schedule(current); // 进行调度
current-&gt;pass += current-&gt;stride; // 将行程值加上步长值
insert(queue, current); // 放回队列
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h3 id="对比" tabindex="-1"><a class="header-anchor" href="#对比" aria-hidden="true">#</a> 对比</h3><p>彩票调度有一个步长调度没有的优势——<strong>不需要全局状态</strong>。</p><p>假如一个新的进程在步长调度执行过程中加入系统，应该怎么设置它的行程值呢？如果设置成0，新来的进程就独占CPU了。</p><p>彩票调度算法不需要对每个进程记录全局状态，只需要用新进程的票数更新全局的总票数就可以了。</p><p>因此彩票调度算法能够更合理地处理新加入的进程。</p><h3 id="总结" tabindex="-1"><a class="header-anchor" href="#总结" aria-hidden="true">#</a> 总结</h3><p>彩票调度和步长调度并没有作为CPU调度程序被广泛使用，原因如下：</p><ul><li>不能很好地适合I/O；</li><li>最难的票数分配问题并没有确定的解决方式，</li></ul><p>比例份额调度程序只有在这些问题可以相对容易解决的领域更有用（例如容易确定份额比例）。例如在虚拟（virtualized）数据中心中，你可能会希望分配1/4的CPU周期给Windows虚拟机，剩余的给Linux系统，比例分配的方式可以更简单高效。</p><h2 id="多处理器调度" tabindex="-1"><a class="header-anchor" href="#多处理器调度" aria-hidden="true">#</a> 多处理器调度</h2><p>现在计算机都是<strong>多核处理器</strong>（multiprocessor），所以要讨论一下<strong>多处理器调度</strong>（multiprocessor scheduling）。</p><p>实际上一个程序只是用一个CPU，多个CPU不会使得程序更快，所以代码中需要使用多线程才能发挥多核的更大优势。多线程应用程序可以将工作扩展到多个CPU上，因此在给定更多的CPU资源时运行得更快。</p><h3 id="多处理体系架构" tabindex="-1"><a class="header-anchor" href="#多处理体系架构" aria-hidden="true">#</a> 多处理体系架构</h3><p>为了理解围绕多处理器调度的新问题，必须了解单cpu硬件和多CPU硬件之间的根本区别。这种差异集中在硬件缓存的使用上，以及如何跨多个处理器共享数据。</p><p>在具有单个CPU的系统中，只存在一个缓存：</p><img src="https://blog-zzys.oss-cn-beijing.aliyuncs.com/articles/3195faa7eb0e894b33d04757f0dbb8ec.png" alt="image-20230811100213192" style="zoom:50%;"><p>关于缓存的知识不再介绍。</p><p>当在多个CPU的时候，就会有<strong>缓存一致性</strong>（cache coherence）的问题。</p><img src="https://blog-zzys.oss-cn-beijing.aliyuncs.com/articles/1ee0b1de4792d1d0c34743333acc7212.png" alt="image-20230811100132884" style="zoom:50%;"><blockquote><p>硬件提供的基本解决方案由硬件提供：通过监控内存访问，硬件可以确保基本上“正确的事情”发生，并保留单个共享内存的视图。在基于总线的系统上（如上所述）上做到这一点的一种方法是使用一种称为<strong>总线窥探</strong>（bus snooping）的旧技术。每个缓存通过观察连接到主内存的总线来注意内存更新。当CPU看到它在缓存中的数据项的更新时，它会注意到更改，并使它的副本失效（即从自己的缓存中删除它）或更新它（即将新值放入缓存中）。回写缓存使这变得更加复杂（因为对主存的写入直到以后才可见）。</p></blockquote><h3 id="同步" tabindex="-1"><a class="header-anchor" href="#同步" aria-hidden="true">#</a> 同步</h3><p>即使硬件已经做了很多对于缓存一致性的问题，软件程序仍然需要去保证共享数据的正确性。如锁，或者无锁并发（可以参见JUC文章）。很明显同步策略是一定会对效率产生影响的。</p><h3 id="缓存亲和性" tabindex="-1"><a class="header-anchor" href="#缓存亲和性" aria-hidden="true">#</a> 缓存亲和性</h3><p>最后一个问题出现在构建多处理器缓存调度器时，称为缓存亲和性。当一个进程在一个特定的CPU上运行时，它会在CPU的缓存（和TLB）中建立一个相当多的状态。下次进程运行时，在相同的CPU上运行它通常是有利的，因为如果它的某些状态已经出现在该CPU上的缓存中了，它就会运行得更快。相反，如果每次在不同的CPU上运行一个进程，那么进程的性能将会更差，因为每次运行时都必须重新加载状态（注意，由于硬件的缓存一致性协议，它将在不同的CPU上正确运行）。因此，多处理器调度器在做出调度决策时应该考虑缓存亲和性，如果可能的话，它可能更倾向于将一个进程保持在同一个CPU上。</p><h3 id="单队列调度" tabindex="-1"><a class="header-anchor" href="#单队列调度" aria-hidden="true">#</a> 单队列调度</h3><p><strong>单队列调度</strong>（single queue multiprocessor scheduling）。SQMS即将所有的任务放入同一个队列，它无需花费太多的工作来选择现有的策略，并使其适应在多个CPU上工作。</p><p>SQMS的第一个问题是缺乏<strong>可扩展性</strong>（scalability），为了确保调度器在多个cpu上正确工作，开发人员将在代码中插入某种形式的锁定，如上所述。锁确保当SQMS代码访问单个队列（例如，查找下一个要运行的作业）时，会出现正确的结果。随着CPU的增加，对于单一锁的竞争会越来越激烈。</p><p>第二个问题是对于缓存亲和性支持度不高，有下面的一个任务队列：</p><img src="https://blog-zzys.oss-cn-beijing.aliyuncs.com/articles/3a1e7d506a6656c14f4a8aa456d4f379.png" alt="image-20230811101740680" style="zoom:67%;"><p>着时间的推移，假设每个作业运行一个时间片，然后选择另一个作业，这里是一个跨cpu的可能的作业计划：</p><img src="https://blog-zzys.oss-cn-beijing.aliyuncs.com/articles/0627e0f5fad69112db122993573a5ad5.png" alt="image-20230811101835983" style="zoom:67%;"><p>为了处理这个问题，大多数SQMS调度程序都包含了某种关联机制，如果可能的话，它试图使该进程更有可能继续在同一CPU上运行。具体来说，可能为一些工作提供亲和力，但移动其他工作以平衡负载。实现方案可能会很复杂，例如：</p><img src="https://blog-zzys.oss-cn-beijing.aliyuncs.com/articles/a5212b13986ab0d6b5cc89e56bac83ed.png" alt="image-20230811102046826" style="zoom:67%;"><p>因此，SQMS的方法也有其优缺点。给定一个现有的单cpu调度器，实现它很简单，根据定义，它只有一个队列。但是，它不能很好地伸缩（由于同步开销），并且不容易保持缓存亲和力。</p><h3 id="多队列调度" tabindex="-1"><a class="header-anchor" href="#多队列调度" aria-hidden="true">#</a> 多队列调度</h3><p>对于每个CPU都有一个队列，将这种方法称为<strong>多队列多处理器调度</strong>（multi-queue multiprocessor scheduling）。</p><p>MQMS扩展性好，对于增加CPU，只需要为它增加对于的队列即可。同时，它在本质上也保证了缓存亲和性。</p><img src="https://blog-zzys.oss-cn-beijing.aliyuncs.com/articles/d974f47be133df1ecb0bbd2c3b6aaf23.png" alt="image-20230811102535304" style="zoom:67%;"><img src="https://blog-zzys.oss-cn-beijing.aliyuncs.com/articles/9cc9dc13d5fdc7588556e1022d356dab.png" alt="image-20230811102549192" style="zoom:67%;"><p>但是MQMS可能会出现<strong>负载不均衡</strong>（ load imbalance）的问题。</p><img src="https://blog-zzys.oss-cn-beijing.aliyuncs.com/articles/0e7850e821da9a2c9e78efc784549db7.png" alt="image-20230811102658160" style="zoom:67%;"><img src="https://blog-zzys.oss-cn-beijing.aliyuncs.com/articles/b80fe406f1dfec5fd6b0fcd482d34d12.png" alt="image-20230811102709509" style="zoom:67%;"><p>甚至还有可能CPU0没有任务，但是CPU1还有很多任务执行。</p><p>这时候就要移动作业。称之为<strong>迁移</strong>（migration）。通过将作业从一个CPU迁移到另一个CPU，可以实现真正的<strong>负载平衡</strong>（load balance）。</p><p>实现迁移策略的一种基本方法是被称为<strong>工作窃取</strong>（work stealing）的技术。作业不足的（源）队列会偶尔查看另一个（目标）队列，以查看其状态。如果目标队列（特别是）比源队列作业更多，那么源队列将从目标队列中“窃取”一个或多个作业，以帮助平衡负载。</p><p>一方面，如果经常查看其他队列，将遭受高开销和缩放困难。另一方面，如果不经常查看其他队列，那么就会面临严重的负载平衡的危险。</p><blockquote><p>linux多处理器调度：</p><ul><li>O(1)：多队列，基于优先级的调度器类似于MLFQ</li><li>CFS：多队列，一种确定性的比例份额方法（更像是步长调度）</li><li>BFS：单队列，也是比例共享，但基于一个更复杂的方案，称为最早合格的虚拟截止日期优先</li></ul></blockquote>`,81);function x(C,P){const e=l("ExternalLinkIcon");return r(),o("div",null,[p,s("blockquote",null,[d,s("p",null,[s("a",m,[a("彻底搞懂孤儿/僵尸/守护进程"),t(e)])])]),u,s("blockquote",null,[s("p",null,[s("a",g,[a("内核堆栈和用户堆栈 小结 - Dormant - 博客园 (cnblogs.com)"),t(e)])])]),h,b,k,y,v,f,z])}const w=i(c,[["render",x],["__file","ostep-virtualization-cpu.html.vue"]]);export{w as default};
